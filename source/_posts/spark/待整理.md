---
    title: 待整理
    categories: spark
    tags:
    creator: cjq
    create_time: 2021/01/06

---

## sparkUI

[Spark UI (1) - Jobs页面](https://km.sankuai.com/page/237242009)

[Spark Web UI 监控详解](https://cloud.tencent.com/developer/article/1582307)



## sparkSQL

[spark sql多维分析优化——细节是魔鬼](https://zhuanlan.zhihu.com/p/78804934)

[从一个sql引发的hive谓词下推的全面复盘及源码分析(上)](https://zhuanlan.zhihu.com/p/78266517)



## 优化

[spark执行map-join优化](https://www.codercto.com/a/66295.html)

[使用Spark进行搜狗日志分析实例——map join的使用](https://www.cnblogs.com/wbh1000/p/9827344.html)

[记录一次spark sql的优化过程](https://zhuanlan.zhihu.com/p/77614511)

[spark sql多维分析优化——提高读取文件的并行度](https://zhuanlan.zhihu.com/p/79737848)

[SparkConfiguration](https://www.cnblogs.com/zyzdisciple/p/12198182.html)

[Spark性能优化指南——高级篇](https://tech.meituan.com/2016/05/12/spark-tuning-pro.html)



## Streaming

[Streaming Join](https://jaceklaskowski.gitbooks.io/spark-structured-streaming/content/spark-sql-streaming-join.html)

[Introducing Stream-Stream Joins in Apache Spark 2.3](https://databricks.com/blog/2018/03/13/introducing-stream-stream-joins-in-apache-spark-2-3.html)



## 架构

[Running Spark on YARN](https://spark.apache.org/docs/latest/running-on-yarn.html)

[Job Scheduling](https://spark.apache.org/docs/latest/job-scheduling.html)

[Spark 如何并行执行多个job](https://blog.csdn.net/zpf336/article/details/102820745)



## 解决方案

[Spark项目实战-数据倾斜解决方案之将reduce join转换为map join](https://blog.csdn.net/anbang713/article/details/82858745)

[Add jars to a Spark Job - spark-submit](https://stackoverflow.com/questions/37132559/add-jars-to-a-spark-job-spark-submit)

spark3 jar加载顺序



use batch or streaming

[5 Minutes Spark Batch Job vs Streaming Job](https://stackoverflow.com/questions/57168267/5-minutes-spark-batch-job-vs-streaming-job)



## 常见错误汇总

[Container xxx is running beyond physical memory limits](https://www.cnblogs.com/Gxiaobai/p/11166986.html)



spark读文件

http://www.waitingfy.com/archives/4325

http://www.waitingfy.com/archives/4342



读文件tips：

1. 可以写路径"path/xxx/*" 来读取全部的文件



本地搭建spark环境



### 原理

[Dynamic resource allocation in Spark](https://www.waitingforcode.com/apache-spark/dynamic-resource-allocation-spark/read)



### 序列化

spark之kryo 序列化

# questions

1. spark batch任务可以并行执行吗
2. spark.streams.awaitAnyTermination()
3. java.lang.RuntimeException: Could not serialize lambda broadcast
4. 
